{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import Dataset\n",
    "import time\n",
    "import os\n",
    "import configparser as ConfigParser\n",
    "import sys\n",
    "import argparse \n",
    "import psutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hallucinator ():    \n",
    "    def __init__ (self,config_file,scale,gpu_num):\n",
    "        print (\"Initializing Hallucinator class\")\n",
    "        self.scale=scale\n",
    "        self.gpu =\"/gpu:{}\".format(gpu_num)\n",
    "        self.readConfiguration(config_file)\n",
    "        self.depth=tf.placeholder(tf.float32,(None,self.imageHeight,self.imageWidth,self.channels),name='depthInput')             \n",
    "        self.rgb  =tf.placeholder(tf.float32,(None,self.imageHeight,self.imageWidth,self.channels),name='grountTruth')\n",
    "        self.dataObj = Dataset.dataReader(self.dataArguments)\n",
    "        if not os.path.exists(self.summary_writer_dir):\n",
    "            os.makedirs(self.summary_writer_dir)\n",
    "        if not os.path.exists(self.modelLocation):\n",
    "            os.makedirs(self.modelLocation)\n",
    "        logPath = os.path.join(self.logDir,self.modelName)\n",
    "        if not os.path.exists(logPath):\n",
    "            os.makedirs(logPath)\n",
    "        self.logDir = os.path.join(logPath,'log.txt')\n",
    "        self.logger = open(self.logDir,'w')\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_num)\n",
    "        self.sess = None\n",
    "        \n",
    "    def readConfiguration(self,config_file):\n",
    "        print (\"Reading configuration File\")\n",
    "        config = ConfigParser.ConfigParser()\n",
    "        config.read(config_file)\n",
    "        self.imageWidth=int(int(config.get('DATA','imageWidth'))/self.scale)\n",
    "        self.imageHeight=int(int(config.get('DATA','imageHeight'))/self.scale)\n",
    "        self.channels=int (config.get('DATA','channels'))\n",
    "        self.train_file = config.get ('DATA','train_file')\n",
    "        self.test_file  = config.get ('DATA','test_file')\n",
    "        self.batchSize  = int(config.get ('DATA','batchSize'))\n",
    "        self.dataArguments = {\"imageWidth\":self.imageWidth,\"imageHeight\":self.imageHeight,\\\n",
    "                              \"channels\" : self.channels, \"batchSize\":self.batchSize,\\\n",
    "                              \"train_file\":self.train_file,\"test_file\":self.test_file,\"scale\":self.scale}    \n",
    "        self.maxEpoch=int(config.get('TRAIN','maxEpoch'))\n",
    "        self.learningRate = float(config.get('TRAIN','learningRate'))\n",
    "        \n",
    "        self.print_freq=int(config.get('LOG','print_freq'))\n",
    "        self.save_freq = int (config.get('LOG','save_freq'))\n",
    "        self.val_freq = int (config.get('LOG','val_freq'))\n",
    "        self.modelName = config.get('LOG','modelName') +\"_s{}\".format(self.scale)\n",
    "        self.modelLocation = config.get('LOG','modelLocation')\n",
    "        self.modelLocation = os.path.join(self.modelLocation , self.modelName)\n",
    "        self.checkPoint =  bool(int(config.get('LOG','checkpoint')))\n",
    "        self.restoreModelPath =config.get('LOG','restoreModelPath')\n",
    "        self.logDir = config.get('LOG','logFile')\n",
    "\n",
    "        if self.checkPoint:\n",
    "            print (\"Using the latest trained model in check point file\")\n",
    "            self.restoreModelPath = tf.train.latest_checkpoint(self.restoreModelPath)\n",
    "        self.summary_writer_dir =os.path.join(config.get('LOG','summary_writer_dir') ,self.modelName)     \n",
    "        \n",
    "        \n",
    "    def generateImage(self):  # Inference procedure\n",
    "        with tf.variable_scope(self.modelName, reuse=tf.AUTO_REUSE):\n",
    "            #layer 1\n",
    "            conv1 = tf.layers.conv2d(inputs=self.depth,filters=147,kernel_size=(11,11), padding=\"same\",name=\"conv1\",kernel_initializer=tf.truncated_normal_initializer)\n",
    "            conv1 = tf.contrib.layers.instance_norm(inputs=conv1)\n",
    "            conv1 = tf.nn.selu(conv1,name=\"conv1_actvn\")\n",
    "            \n",
    "            #layer 2\n",
    "            conv2 = tf.layers.conv2d(inputs=conv1,filters=36,kernel_size=(11,11),padding=\"same\",name=\"conv2\",kernel_initializer=tf.truncated_normal_initializer)\n",
    "            conv2 = tf.contrib.layers.instance_norm(inputs=conv2)\n",
    "            conv2 = tf.nn.selu(conv2,name='conv2_actvn')\n",
    "            \n",
    "            #layer 3\n",
    "            conv3 = tf.layers.conv2d(inputs=conv2,filters=36,kernel_size=(11,11),padding=\"same\",name=\"conv3\",kernel_initializer=tf.truncated_normal_initializer)\n",
    "            conv3 = tf.contrib.layers.instance_norm(inputs=conv3)\n",
    "            conv3 = tf.nn.selu(conv3,name='conv3_actvn')\n",
    "            \n",
    "            #layer 4\n",
    "            conv4 =  tf.layers.conv2d(inputs=conv3,filters=36,kernel_size=(11,11),padding=\"same\",name=\"conv4\",kernel_initializer=tf.truncated_normal_initializer)\n",
    "            conv4 = tf.contrib.layers.instance_norm(inputs=conv4)\n",
    "            conv4 = tf.nn.selu(conv4,name=\"conv4_actvn\")\n",
    "            \n",
    "            #layer 5\n",
    "            conv5 = tf.layers.conv2d(inputs=conv4,filters=36,kernel_size=(11,11),padding=\"same\",name=\"conv5\",kernel_initializer=tf.truncated_normal_initializer)\n",
    "            conv5 = tf.contrib.layers.instance_norm(inputs=conv5)\n",
    "            conv5 = tf.nn.selu(conv5,name=\"conv5_actvn\")\n",
    "            \n",
    "            #layer 6 \n",
    "            conv6 = tf.layers.conv2d(inputs=conv5,filters=36,kernel_size=(11,11),padding=\"same\",name=\"conv6\",kernel_initializer=tf.truncated_normal_initializer)\n",
    "            conv6 = tf.contrib.layers.instance_norm(inputs=conv6)\n",
    "            conv6 = tf.nn.selu(conv6,name=\"conv6_actvn\")\n",
    "            \n",
    "            #layer 7\n",
    "            conv7 = tf.layers.conv2d(inputs=conv6,filters=36,kernel_size=(11,11),padding=\"same\",name=\"conv7\",kernel_initializer=tf.truncated_normal_initializer)\n",
    "            conv7 = tf.contrib.layers.instance_norm(inputs=conv7)\n",
    "            conv7 = tf.nn.selu(conv7,name=\"conv7_actvn\")\n",
    "            \n",
    "            #layer 8\n",
    "            conv8 = tf.layers.conv2d(inputs=conv7,filters=36,kernel_size=(11,11),padding=\"same\",name=\"conv8\",kernel_initializer=tf.truncated_normal_initializer)\n",
    "            conv8 = tf.contrib.layers.instance_norm(inputs=conv8)\n",
    "            conv8 = tf.nn.selu(conv8,name=\"conv8_actvn\")\n",
    "            \n",
    "            #layer 9 \n",
    "            conv9 = tf.layers.conv2d(inputs=conv8,filters=36,kernel_size=(11,11),padding=\"same\",name=\"conv9\",kernel_initializer=tf.truncated_normal_initializer)\n",
    "            conv9 = tf.contrib.layers.instance_norm(inputs=conv9)\n",
    "            conv9 = tf.nn.selu(conv9,name=\"conv9_actvn\")\n",
    "            \n",
    "            #layer 10\n",
    "            conv10 = tf.layers.conv2d(inputs=conv9,filters=147,kernel_size=(11,11),padding=\"same\",name=\"conv10\",kernel_initializer=tf.truncated_normal_initializer)\n",
    "            conv10 = tf.contrib.layers.instance_norm(inputs=conv10)\n",
    "            conv10 = tf.nn.selu(conv10,name=\"conv10_actvn\")\n",
    "            \n",
    "            #Image generation layer \n",
    "            outH = tf.layers.conv2d(inputs=conv10,filters=3,kernel_size=(11,11),padding=\"same\",name=\"output\",kernel_initializer=tf.truncated_normal_initializer)\n",
    "            return outH\n",
    "        \n",
    "        \n",
    "    def train(self):      \n",
    "        #with tf.device(self.gpu):\n",
    "        self.outH=self.generateImage()\n",
    "        loss= self.loss()\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=self.learningRate)\n",
    "        Trainables=optimizer.minimize(loss)\n",
    "        valid_image_summary =tf.summary.image('test_image_output',self.outH)\n",
    "        loss_summary = tf.summary.scalar('Loss',loss)\n",
    "        iters=0\n",
    "        self.saver = tf.train.Saver()\n",
    "        config=tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth=True\n",
    "        self.sess = tf.Session(config=config)\n",
    "        train_summary_writer=tf.summary.FileWriter(os.path.join(self.summary_writer_dir,'train'),self.sess.graph)\n",
    "        test_summary_writer=tf.summary.FileWriter(os.path.join(self.summary_writer_dir,'test'),self.sess.graph)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        process = psutil.Process(os.getpid())\n",
    "        while not self.dataObj.epoch == self.maxEpoch :\n",
    "            iters+=1\n",
    "            inp,gt = self.dataObj.nextTrainBatch()\n",
    "            loss = self.loss()\n",
    "            t1=time.time()\n",
    "            _,lval,t_summaries = self.sess.run([Trainables,loss,loss_summary], feed_dict= {self.depth : inp,self.rgb : gt})\n",
    "            train_summary_writer.add_summary(t_summaries,iters)\n",
    "            t2=time.time()         \n",
    "            \n",
    "            \n",
    "            print(process.memory_info().rss/100000.)\n",
    "            if not iters % self.print_freq:\n",
    "                info = \"Model Hallucinatore_s{} Epoch  {} : Iteration : {}/{} loss value : {:0.4f} Time per batch : {:0.3f}s \\n\".format(self.scale,self.dataObj.epoch,iters,(self.dataObj.epoch+1)*int(self.dataObj.dataLength/self.dataObj.batchSize),lval,t2-t1)\n",
    "                print (info)   \n",
    "                self.logger.write(info)\n",
    "            if not iters % self.save_freq:\n",
    "                info=\"Model Saved at iteration {}\\n\".format(iters)\n",
    "                print (info)\n",
    "                self.logger.write(info)\n",
    "                self.saveModel(iters)\n",
    "                \n",
    "            if not iters % self.val_freq :\n",
    "                val_inp,val_gt  = self.dataObj.nextTestBatch()\n",
    "                val_loss,v_summaries,v_img_summaries = self.sess.run([loss,loss_summary,valid_image_summary],feed_dict={self.depth : val_inp,self.rgb : val_gt})\n",
    "                test_summary_writer.add_summary(v_summaries, iters)\n",
    "                test_summary_writer.add_summary(v_img_summaries,iters)\n",
    "                info = \"Validation Loss at iteration{} : {}\\n\".format(iters, val_loss)\n",
    "                print (info)\n",
    "                self.logger.write(info)\n",
    "        print (\"Training done \")\n",
    "        self.logger.close()\n",
    "    \n",
    "    def testAll(self):\n",
    "        self.restoreModel()\n",
    "        loss=[]\n",
    "        while not self.dataObj.test_epoch == 1 :\n",
    "            x,y = self.dataObj.nextTestBatch()\n",
    "            l = self.sess.run(self.loss(),feed_dict= {self.depth : x, self.rgb :y})\n",
    "            loss.append(l)\n",
    "        return np.mean(loss)\n",
    "        \n",
    "    def getHallucinatedImages(self,image_list):\n",
    "        with tf.device(self.gpu):\n",
    "            self.restoreModel()\n",
    "            img_processed= self.dataObj.preProcessImages(image_list)\n",
    "            generator = self.generateImage()\n",
    "            output = self.sess.run(generator,{self.depth:img_processed})\n",
    "            return output\n",
    "    \n",
    "    def loss(self):\n",
    "        return tf.reduce_mean(2*tf.nn.l2_loss(self.outH-self.rgb))/(self.imageHeight*self.imageWidth*self.dataObj.batchSize*self.channels)   \n",
    "    def smoothing_loss(self):\n",
    "        I_Hgrad = tf.images\n",
    "    def saveModel(self,iters):\n",
    "        if not os.path.exists (self.modelLocation):\n",
    "            os.makedirs(self.modelLocation)\n",
    "        self.saver.save(self.sess,os.path.join(self.modelLocation,self.modelName),global_step = iters)\n",
    "        \n",
    "    def restoreModel(self):\n",
    "        print (self.modelLocation)\n",
    "        if not self.sess is None:\n",
    "            if self.sess._opened :\n",
    "                self.sess.close()\n",
    "        sess=tf.Session()\n",
    "        self.outH=self.generateImage()\n",
    "        sav=tf.train.Saver()\n",
    "        sav.restore(sess,self.restoreModelPath)\n",
    "        self.sess = sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Hallucinator class\n",
      "Reading configuration File\n",
      "Using the latest trained model in check point file\n",
      "Initializing Data Reader\n",
      "Train files 108256\n",
      "Test  files 27064\n",
      "Initialization Complete\n",
      "/home/kgunase3/data/NYUD/models/rgbHallucination_L2_1_s8\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'AUTO_REUSE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-574c66f75b7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHallucinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"config.ini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-6bad4373df9b>\u001b[0m in \u001b[0;36mtestAll\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtestAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestoreModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6bad4373df9b>\u001b[0m in \u001b[0;36mrestoreModel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerateImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0msav\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0msav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestoreModelPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6bad4373df9b>\u001b[0m in \u001b[0;36mgenerateImage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerateImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Inference procedure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTO_REUSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;31m#layer 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m147\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conv1\"\u001b[0m\u001b[0;34m,\u001b[0m                                         \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'AUTO_REUSE'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    sys.argv=['RGBHallucinator','8','0']\n",
    "    parser =  argparse.ArgumentParser(description = \"Mention the scale and GPU parameters\")\n",
    "    parser.add_argument('scale',type = int ,help = \" What scale do you want to train it at \")\n",
    "    parser.add_argument('gpu',type = int,help = \" Which GPU do you want to train it in \")\n",
    "    args= parser.parse_args()\n",
    "    scale=args.scale\n",
    "    gpu  =args.gpu\n",
    "    tf.reset_default_graph()\n",
    "    H = Hallucinator(\"config.ini\",scale,gpu)\n",
    "    H.testAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# h=Hallucinator(\"config.ini\",1,0)\n",
    "# inp,gt = h.dataObj.nextTestBatch()\n",
    "\n",
    "# edge= tf.image.sobel_edges(h.rgb)\n",
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# out,edge = sess.run([h.rgb,edge],feed_dict = {h.rgb:gt})\n",
    "# sess.close()\n",
    "# plt.imshow(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print edge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a=edge[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y = a[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.imshow(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = a[:,:,:,1]\n",
    "# plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
